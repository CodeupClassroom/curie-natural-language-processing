{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Text\n",
    "\n",
    "Parsing text means to break it down into its parts. If we diagram the nouns, verbs, and tense in language, we're parsing using grammatical rules. Because natural language has so many rules and edge cases, when we approach things with NLP, we're looking to apply \n",
    "\n",
    "## Big Idea \n",
    "- We want to reduce the variability between words. \n",
    "- Both \"math\" and \"Math\" mean the same thing, so we lowercase things to reduce the variability of the same exact term.\n",
    "- `Erdős`, `Erdös`, and `Erdos` refer to the same person. Again, we're looking to reduce variability before we start searching for relationships between values.\n",
    "\n",
    "### Workflow:\n",
    "1. Convert all text to lowercase\n",
    "2. Remove accented characters and non-ASCII characters\n",
    "3. Remove special characters\n",
    "4. Stem or lemmatize the words (Prefer Lemmatizing since it captures more meaning)\n",
    "5. Remove stopwords\n",
    "6. Store the transformed text as well as the original text for future use.\n",
    "\n",
    "### Terms, libraries, and concepts\n",
    "- Normalizing text - Text normalization is the process of transforming text into a single canonical form that it might not have had before. Text normalization requires being aware of what type of text is to be normalized and how it is to be processed afterwards; there is no all-purpose normalization procedure\n",
    "- tokenization\n",
    "- corpus - body\n",
    "- stem\n",
    "- lemmatize\n",
    "- stopwords (a, an, the, for, of, etc...)\n",
    "- ASCII and non-ASCII characters\n",
    "- .encode to ASCII - ASCII is  a short list of 128 characters and numbers\n",
    "- .decode to utf-8 - converting back to normal Python strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = \"Paul Erdős and George Pólya are influential Hungarian mathematicians who contributed a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field. erdos's name contains the hungarian letter 'o' ('o' with double acute accent), but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercase and remove accented characters and any non-ASCII characters\n",
    "# Encode to ASCII, to convert special characters into ASCII \n",
    "# Decode from ASCII to UTF-8 so we have a normal Python string\n",
    "string = original.lower()\n",
    "string = unicodedata.normalize('NFKD', string)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')    \n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field erdos's name contains the hungarian letter 'o' 'o' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any special characters and replace with an empty string\n",
    "string = re.sub(r\"[^a-z0-9'\\s]\", '', string)\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paul erdos and george polya are influential hungarian mathematicians who contributed a lot to the field erdos ' s name contains the hungarian letter ' o ' ' o ' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\n"
     ]
    }
   ],
   "source": [
    "# We can accomplish the above two step by using a tokenizer\n",
    "tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "print(tokenizer.tokenize(string, return_str=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('call', 'call', 'call')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming is a super basic way to get only the \"stem\" of a word\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "ps.stem('call'), ps.stem('called'), ps.stem('calling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'erdo',\n",
       " 'and',\n",
       " 'georg',\n",
       " 'polya',\n",
       " 'are',\n",
       " 'influenti',\n",
       " 'hungarian',\n",
       " 'mathematician',\n",
       " 'who',\n",
       " 'contribut',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'to',\n",
       " 'the',\n",
       " 'field',\n",
       " \"erdos'\",\n",
       " 'name',\n",
       " 'contain',\n",
       " 'the',\n",
       " 'hungarian',\n",
       " 'letter',\n",
       " \"'o'\",\n",
       " \"'o'\",\n",
       " 'with',\n",
       " 'doubl',\n",
       " 'acut',\n",
       " 'accent',\n",
       " 'but',\n",
       " 'is',\n",
       " 'often',\n",
       " 'incorrectli',\n",
       " 'written',\n",
       " 'as',\n",
       " 'erdo',\n",
       " 'or',\n",
       " 'erdo',\n",
       " 'either',\n",
       " 'by',\n",
       " 'mistak',\n",
       " 'or',\n",
       " 'out',\n",
       " 'of',\n",
       " 'typograph',\n",
       " 'necess']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems = [ps.stem(word) for word in string.split()]\n",
    "stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [wnl.lemmatize(word) for word in string.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'erdos',\n",
       " 'and',\n",
       " 'george',\n",
       " 'polya',\n",
       " 'are',\n",
       " 'influential',\n",
       " 'hungarian',\n",
       " 'mathematician',\n",
       " 'who',\n",
       " 'contributed',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'to',\n",
       " 'the',\n",
       " 'field',\n",
       " \"erdos's\",\n",
       " 'name',\n",
       " 'contains',\n",
       " 'the',\n",
       " 'hungarian',\n",
       " 'letter',\n",
       " \"'o'\",\n",
       " \"'o'\",\n",
       " 'with',\n",
       " 'double',\n",
       " 'acute',\n",
       " 'accent',\n",
       " 'but',\n",
       " 'is',\n",
       " 'often',\n",
       " 'incorrectly',\n",
       " 'written',\n",
       " 'a',\n",
       " 'erdos',\n",
       " 'or',\n",
       " 'erdos',\n",
       " 'either',\n",
       " 'by',\n",
       " 'mistake',\n",
       " 'or',\n",
       " 'out',\n",
       " 'of',\n",
       " 'typographical',\n",
       " 'necessity']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'erdos',\n",
       " 'and',\n",
       " 'george',\n",
       " 'polya',\n",
       " 'are',\n",
       " 'influential',\n",
       " 'hungarian',\n",
       " 'mathematician',\n",
       " 'who',\n",
       " 'contributed',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'to',\n",
       " 'the',\n",
       " 'field',\n",
       " \"erdos's\",\n",
       " 'name',\n",
       " 'contains',\n",
       " 'the',\n",
       " 'hungarian',\n",
       " 'letter',\n",
       " \"'o'\",\n",
       " \"'o'\",\n",
       " 'with',\n",
       " 'double',\n",
       " 'acute',\n",
       " 'accent',\n",
       " 'but',\n",
       " 'is',\n",
       " 'often',\n",
       " 'incorrectly',\n",
       " 'written',\n",
       " 'a',\n",
       " 'erdos',\n",
       " 'or',\n",
       " 'erdos',\n",
       " 'either',\n",
       " 'by',\n",
       " 'mistake',\n",
       " 'or',\n",
       " 'out',\n",
       " 'of',\n",
       " 'typographical',\n",
       " 'necessity']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'erdo',\n",
       " 'georg',\n",
       " 'polya',\n",
       " 'influenti',\n",
       " 'hungarian',\n",
       " 'mathematician',\n",
       " 'contribut',\n",
       " 'lot',\n",
       " 'field',\n",
       " \"erdos'\",\n",
       " 'name',\n",
       " 'contain',\n",
       " 'hungarian',\n",
       " 'letter',\n",
       " \"'o'\",\n",
       " \"'o'\",\n",
       " 'doubl',\n",
       " 'acut',\n",
       " 'accent',\n",
       " 'often',\n",
       " 'incorrectli',\n",
       " 'written',\n",
       " 'erdo',\n",
       " 'erdo',\n",
       " 'either',\n",
       " 'mistak',\n",
       " 'typograph',\n",
       " 'necess']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_stems = [w for w in stems if w not in stopword_list]\n",
    "clean_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paul',\n",
       " 'erdos',\n",
       " 'george',\n",
       " 'polya',\n",
       " 'influential',\n",
       " 'hungarian',\n",
       " 'mathematician',\n",
       " 'contributed',\n",
       " 'lot',\n",
       " 'field',\n",
       " \"erdos's\",\n",
       " 'name',\n",
       " 'contains',\n",
       " 'hungarian',\n",
       " 'letter',\n",
       " \"'o'\",\n",
       " \"'o'\",\n",
       " 'double',\n",
       " 'acute',\n",
       " 'accent',\n",
       " 'often',\n",
       " 'incorrectly',\n",
       " 'written',\n",
       " 'erdos',\n",
       " 'erdos',\n",
       " 'either',\n",
       " 'mistake',\n",
       " 'typographical',\n",
       " 'necessity']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_lemmas = [w for w in lemmas if w not in stopword_list]\n",
    "clean_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
